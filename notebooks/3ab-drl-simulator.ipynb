{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31240,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AoI Graph Freshness with GNN-DQN\nNotebook for Part 3a and Part 3b","metadata":{}},{"cell_type":"code","source":"import os, random, math\nimport numpy as np\nimport networkx as nx\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"device:\", device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-22T05:07:26.784746Z","iopub.execute_input":"2025-12-22T05:07:26.785009Z","iopub.status.idle":"2025-12-22T05:07:31.702298Z","shell.execute_reply.started":"2025-12-22T05:07:26.784969Z","shell.execute_reply":"2025-12-22T05:07:31.701511Z"}},"outputs":[{"name":"stdout","text":"device: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch, sys, platform\n\nprint(\"Python:\", sys.version)\nprint(\"Platform:\", platform.platform())\nprint(\"Torch:\", torch.__version__)\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"torch.version.cuda:\", torch.version.cuda)\n\ndef pyg_wheel_url():\n    tv = torch.__version__.split(\"+\")[0]  # \"2.2.1\"\n    if torch.cuda.is_available() and torch.version.cuda is not None:\n        cu = \"cu\" + torch.version.cuda.replace(\".\", \"\")\n    else:\n        cu = \"cpu\"\n    return f\"https://data.pyg.org/whl/torch-{tv}+{cu}.html\"\n\nurl = pyg_wheel_url()\nprint(\"PyG wheel URL:\", url)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T05:08:12.829040Z","iopub.execute_input":"2025-12-22T05:08:12.829697Z","iopub.status.idle":"2025-12-22T05:08:12.835543Z","shell.execute_reply.started":"2025-12-22T05:08:12.829675Z","shell.execute_reply":"2025-12-22T05:08:12.834777Z"}},"outputs":[{"name":"stdout","text":"Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\nPlatform: Linux-6.6.105+-x86_64-with-glibc2.35\nTorch: 2.6.0+cu124\nCUDA available: True\ntorch.version.cuda: 12.4\nPyG wheel URL: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import sys\n!{sys.executable} -m pip install -q torch_geometric -f {url}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T05:08:21.792874Z","iopub.execute_input":"2025-12-22T05:08:21.793179Z","iopub.status.idle":"2025-12-22T05:08:27.721253Z","shell.execute_reply.started":"2025-12-22T05:08:21.793156Z","shell.execute_reply":"2025-12-22T05:08:27.720375Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch_geometric\nfrom torch_geometric.nn import GCNConv\nfrom torch_geometric.data import Data\n\nprint(\"torch_geometric:\", torch_geometric.__version__)\n\n# tiny graph: 3 nodes, edges 0-1, 1-2 (undirected)\nedge_index = torch.tensor([[0,1,1,2],\n                           [1,0,2,1]], dtype=torch.long)\nx = torch.randn(3, 4)  # node features\n\ndata = Data(x=x, edge_index=edge_index)\n\nconv = GCNConv(4, 8)\nout = conv(data.x, data.edge_index)\nprint(\"GCNConv OK, out shape:\", out.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T05:08:37.644450Z","iopub.execute_input":"2025-12-22T05:08:37.645328Z","iopub.status.idle":"2025-12-22T05:08:48.012415Z","shell.execute_reply.started":"2025-12-22T05:08:37.645294Z","shell.execute_reply":"2025-12-22T05:08:48.011605Z"}},"outputs":[{"name":"stdout","text":"torch_geometric: 2.7.0\nGCNConv OK, out shape: torch.Size([3, 8])\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Common setup and environment","metadata":{}},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom typing import Optional, Tuple\nimport numpy as np\nimport networkx as nx\n\n@dataclass\nclass AoIEnvConfig:\n    num_nodes: int = 10\n    p: float = 0.8\n    lambda_cost: float = 0.0\n    max_age: int = 100\n    max_steps: int = 50\n    init_age_low: int = 0\n    init_age_high: int = 10\n    graph_type: str = \"line\"\n    seed: int = 42\n\nclass AoIEnv:\n    def __init__(self, config: AoIEnvConfig):\n        self.cfg = config\n        self.rng = np.random.RandomState(config.seed)\n        self._build_graph()\n        self.num_nodes = self.graph.number_of_nodes()\n        self.state = None\n        self.step_count = 0\n        self.action_n = self.num_nodes\n\n    def _build_graph(self):\n        if self.cfg.graph_type == \"line\":\n            G = nx.path_graph(self.cfg.num_nodes)\n        elif self.cfg.graph_type == \"star\":\n            G = nx.star_graph(self.cfg.num_nodes - 1) \n        elif self.cfg.graph_type == \"erdos\":\n            while True:\n                G = nx.erdos_renyi_graph(self.cfg.num_nodes, 0.3, seed=self.cfg.seed)\n                if nx.is_connected(G):\n                    break\n        else:\n            raise ValueError(f\"Unknown graph_type: {self.cfg.graph_type}\")\n        self.graph = G\n\n    def reset(self, init_ages: Optional[np.ndarray] = None) -> np.ndarray:\n        self.step_count = 0\n        if init_ages is None:\n            ages = self.rng.randint(self.cfg.init_age_low, self.cfg.init_age_high + 1, size=self.num_nodes)\n        else:\n            ages = np.array(init_ages, dtype=np.float32)\n        self.state = ages.astype(np.float32)\n        return self.state.copy()\n\n    def step(self, action: int) -> Tuple[np.ndarray, float, bool, dict]:\n        assert 0 <= action < self.num_nodes\n        ages = self.state.astype(np.float32)\n\n        ages = ages + 1.0\n        ages[action] = 0.0\n\n        for j in self.graph.neighbors(action):\n            if self.rng.rand() < self.cfg.p:\n                ages[j] = 0.0\n\n        ages = np.clip(ages, 0.0, float(self.cfg.max_age))\n        self.state = ages\n        self.step_count += 1\n\n        avg_aoi = float(np.mean(self.state))\n        reward = -avg_aoi - self.cfg.lambda_cost\n        done = self.step_count >= self.cfg.max_steps\n        info = {\"avg_aoi\": avg_aoi, \"step\": self.step_count, \"action\": action}\n        return self.state.copy(), reward, done, info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T05:09:44.893443Z","iopub.execute_input":"2025-12-22T05:09:44.894450Z","iopub.status.idle":"2025-12-22T05:09:44.905891Z","shell.execute_reply.started":"2025-12-22T05:09:44.894419Z","shell.execute_reply":"2025-12-22T05:09:44.905067Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import numpy as np\n\ndef random_policy(state, env):\n    return env.rng.randint(env.action_n)\n\ndef greedy_stale_policy(state, env):\n    return int(np.argmax(state))\n\ndef degree_weighted_policy(state, env):\n    deg = np.array([env.graph.degree[i] for i in range(env.num_nodes)], dtype=np.float32)\n    return int(np.argmax(state * deg))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T05:09:50.499277Z","iopub.execute_input":"2025-12-22T05:09:50.500055Z","iopub.status.idle":"2025-12-22T05:09:50.505057Z","shell.execute_reply.started":"2025-12-22T05:09:50.500007Z","shell.execute_reply":"2025-12-22T05:09:50.504272Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def evaluate(env, policy_fn, episodes=50):\n    ms = []\n    for _ in range(episodes):\n        s = env.reset()\n        aoi_sum = 0.0\n        for _ in range(env.cfg.max_steps):\n            a = policy_fn(s, env)\n            s, r, done, info = env.step(a)\n            aoi_sum += info[\"avg_aoi\"]\n            if done:\n                break\n        ms.append(aoi_sum / env.cfg.max_steps)\n    return float(np.mean(ms)), float(np.std(ms))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch_geometric.data import Data\n\ndef nx_to_edge_index(G: nx.Graph) -> torch.Tensor:\n    edges = []\n    for u, v in G.edges():\n        edges.append((u, v))\n        edges.append((v, u))  # make it directed both ways\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    return edge_index\n\ndef make_pyg_data(env: AoIEnv, state: np.ndarray, device: torch.device) -> Data:\n    N = env.num_nodes\n    age = torch.tensor(state / float(env.cfg.max_age),\n                       dtype=torch.float32, device=device).view(N, 1)\n    x = torch.cat([age, env._deg], dim=1)  # [N,2]\n    return Data(x=x, edge_index=env._edge_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T05:46:11.641426Z","iopub.execute_input":"2025-12-22T05:46:11.641714Z","iopub.status.idle":"2025-12-22T05:46:11.647566Z","shell.execute_reply.started":"2025-12-22T05:46:11.641695Z","shell.execute_reply":"2025-12-22T05:46:11.646831Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def cache_graph_tensors(env, device):\n    # edge_index считаем один раз\n    env._edge_index = nx_to_edge_index(env.graph).to(device)\n\n    # degree считаем один раз\n    N = env.num_nodes\n    env._deg = torch.tensor(\n        [env.graph.degree[i] / float(max(1, N-1)) for i in range(N)],\n        dtype=torch.float32, device=device\n    ).view(N, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T05:46:12.029286Z","iopub.execute_input":"2025-12-22T05:46:12.029554Z","iopub.status.idle":"2025-12-22T05:46:12.034166Z","shell.execute_reply.started":"2025-12-22T05:46:12.029536Z","shell.execute_reply":"2025-12-22T05:46:12.033370Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import torch.nn as nn\nfrom torch_geometric.nn import GCNConv\n\nclass GNNQNet(nn.Module):\n    def __init__(self, in_dim=2, hidden=64):\n        super().__init__()\n        self.conv1 = GCNConv(in_dim, hidden)\n        self.conv2 = GCNConv(hidden, hidden)\n        self.head  = nn.Linear(hidden, 1)  # per-node Q\n\n    def forward(self, data: Data) -> torch.Tensor:\n        x, edge_index = data.x, data.edge_index\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        q = self.head(x).squeeze(-1)  # [N]\n        return q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T05:46:15.434439Z","iopub.execute_input":"2025-12-22T05:46:15.434706Z","iopub.status.idle":"2025-12-22T05:46:15.440069Z","shell.execute_reply.started":"2025-12-22T05:46:15.434687Z","shell.execute_reply":"2025-12-22T05:46:15.439352Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import random\nfrom collections import deque\n\nclass ReplayBuffer:\n    def __init__(self, capacity=20000):\n        self.buf = deque(maxlen=capacity)\n\n    def push(self, s, a, r, ns, done):\n        self.buf.append((s, a, r, ns, done))\n\n    def sample(self, batch_size):\n        batch = random.sample(self.buf, batch_size)\n        s, a, r, ns, done = map(np.array, zip(*batch))\n        return s, a, r, ns, done\n\n    def __len__(self):\n        return len(self.buf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T05:46:16.838140Z","iopub.execute_input":"2025-12-22T05:46:16.838402Z","iopub.status.idle":"2025-12-22T05:46:16.843478Z","shell.execute_reply.started":"2025-12-22T05:46:16.838384Z","shell.execute_reply":"2025-12-22T05:46:16.842830Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## Part 3a  Stable GNN-DQN on fixed graph types","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nfrom torch_geometric.data import Batch\n\ndef make_pyg_batch(env, states_np, device):\n    data_list = [make_pyg_data(env, s, device) for s in states_np]\n    return Batch.from_data_list(data_list)\n\ndef train_gnn_dqn_stable(env: AoIEnv,\n                         episodes=300,\n                         gamma=0.99,\n                         lr=3e-4,\n                         batch_size=64,\n                         buffer_size=20000,\n                         warmup=800,\n                         target_update=400,\n                         eps_start=1.0,\n                         eps_end=0.05,\n                         eps_decay=0.995,\n                         device=torch.device(\"cpu\")):\n\n    q_net = GNNQNet(in_dim=2, hidden=64).to(device)\n    target_net = GNNQNet(in_dim=2, hidden=64).to(device)\n    target_net.load_state_dict(q_net.state_dict())\n    target_net.eval()\n\n    opt = optim.Adam(q_net.parameters(), lr=lr)\n    loss_fn = torch.nn.SmoothL1Loss()  # Huber\n    rb = ReplayBuffer(buffer_size)\n\n    total_steps = 0\n    eps = eps_start\n    N = env.num_nodes\n\n    for ep in range(episodes):\n        s = env.reset()\n        for t in range(env.cfg.max_steps):\n            if random.random() < eps:\n                a = random.randrange(env.action_n)\n            else:\n                with torch.no_grad():\n                    data = make_pyg_data(env, s, device)\n                    q = q_net(data)\n                    a = int(torch.argmax(q).item())\n\n            ns, r, done, info = env.step(a)\n            rb.push(s, a, r, ns, done)\n            s = ns\n\n            if len(rb) >= max(warmup, batch_size):\n                bs, ba, br, bns, bd = rb.sample(batch_size)\n\n                batch_s = make_pyg_batch(env, bs, device)\n                q_all = q_net(batch_s).view(batch_size, N)\n                ba_t = torch.tensor(ba, dtype=torch.long, device=device)\n                q_sa = q_all[torch.arange(batch_size, device=device), ba_t]\n\n                with torch.no_grad():\n                    batch_ns = make_pyg_batch(env, bns, device)\n                    q_next = target_net(batch_ns).view(batch_size, N)\n                    q_next_max = q_next.max(dim=1).values\n\n                    br_t = torch.tensor(br, dtype=torch.float32, device=device)\n                    bd_t = torch.tensor(bd.astype(np.float32), dtype=torch.float32, device=device)\n                    target = br_t + gamma * (1.0 - bd_t) * q_next_max\n\n                loss = loss_fn(q_sa, target)\n                opt.zero_grad()\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(q_net.parameters(), 5.0)\n                opt.step()\n\n            total_steps += 1\n            if total_steps % target_update == 0:\n                target_net.load_state_dict(q_net.state_dict())\n\n            if done:\n                break\n\n        eps = max(eps_end, eps * eps_decay)\n        if (ep + 1) % 25 == 0:\n            print(\"episode\", ep + 1, \"eps\", round(eps, 3))\n\n    return q_net","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T06:20:19.117499Z","iopub.execute_input":"2025-12-22T06:20:19.117987Z","iopub.status.idle":"2025-12-22T06:20:19.129309Z","shell.execute_reply.started":"2025-12-22T06:20:19.117966Z","shell.execute_reply":"2025-12-22T06:20:19.128575Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def gnn_policy_from_net(q_net, device):\n    def pol(s, env):\n        with torch.no_grad():\n            data = make_pyg_data(env, s, device)\n            q = q_net(data)\n            return int(torch.argmax(q).item())\n    return pol\n\ndef action_hist(env, policy_fn, episodes=30):\n    counts = np.zeros(env.num_nodes, dtype=int)\n    for _ in range(episodes):\n        s = env.reset()\n        for _ in range(env.cfg.max_steps):\n            a = policy_fn(s, env)\n            counts[a] += 1\n            s, r, done, info = env.step(a)\n            if done:\n                break\n    print(\"action counts:\", counts)\n    print(\"action probs :\", np.round(counts / counts.sum(), 3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T06:20:28.789252Z","iopub.execute_input":"2025-12-22T06:20:28.789837Z","iopub.status.idle":"2025-12-22T06:20:28.795065Z","shell.execute_reply.started":"2025-12-22T06:20:28.789818Z","shell.execute_reply":"2025-12-22T06:20:28.794469Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"### What happens here\nWe train a GNN-DQN on a fixed graph type and compare it against simple baselines.","metadata":{}},{"cell_type":"code","source":"to_run = [\"line\", \"erdos\"]\n\nfor gtype in to_run:\n    cfg = AoIEnvConfig(num_nodes=10, graph_type=gtype, p=0.8, max_steps=50, seed=42)\n    env = AoIEnv(cfg)\n    cache_graph_tensors(env, device)\n\n    print(f\"\\nTraining STABLE GNN-DQN on {gtype}...\")\n    q_net_stable = train_gnn_dqn_stable(env, episodes=300, device=device)\n\n    pols = {\n        \"random\": random_policy,\n        \"greedy\": greedy_stale_policy,\n        \"degree_weighted\": degree_weighted_policy,\n        \"gnn_dqn_stable\": gnn_policy_from_net(q_net_stable, device),\n    }\n\n    for name, pol in pols.items():\n        m, sd = evaluate(env, pol, episodes=50)\n        print(f\"{gtype:5s} | {name:16s} mean_AoI={m:.3f} ± {sd:.3f}\")\n\n    print(\"\\nAction histogram for stable policy:\")\n    action_hist(env, gnn_policy_from_net(q_net_stable, device), episodes=30)\n\n    # optional save\n    import os\n    os.makedirs(\"artifacts\", exist_ok=True)\n    torch.save(q_net_stable.state_dict(), f\"artifacts/gnn_dqn_stable_{gtype}.pt\")\n    print(\"Saved weights to:\", f\"artifacts/gnn_dqn_stable_{gtype}.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T06:20:37.374796Z","iopub.execute_input":"2025-12-22T06:20:37.375487Z","iopub.status.idle":"2025-12-22T06:31:56.558756Z","shell.execute_reply.started":"2025-12-22T06:20:37.375462Z","shell.execute_reply":"2025-12-22T06:31:56.557875Z"}},"outputs":[{"name":"stdout","text":"\nTraining STABLE GNN-DQN on line...\nepisode 25 eps 0.882\nepisode 50 eps 0.778\nepisode 75 eps 0.687\nepisode 100 eps 0.606\nepisode 125 eps 0.534\nepisode 150 eps 0.471\nepisode 175 eps 0.416\nepisode 200 eps 0.367\nepisode 225 eps 0.324\nepisode 250 eps 0.286\nepisode 275 eps 0.252\nepisode 300 eps 0.222\nline  | random           mean_AoI=3.335 ± 0.376\nline  | greedy           mean_AoI=2.097 ± 0.105\nline  | degree_weighted  mean_AoI=2.018 ± 0.113\nline  | gnn_dqn_stable   mean_AoI=2.390 ± 0.167\n\nAction histogram for stable policy:\naction counts: [214   0   0 488  46  73 464   0   0 215]\naction probs : [0.143 0.    0.    0.325 0.031 0.049 0.309 0.    0.    0.143]\nSaved weights to: artifacts/gnn_dqn_stable_line.pt\n\nTraining STABLE GNN-DQN on erdos...\nepisode 25 eps 0.882\nepisode 50 eps 0.778\nepisode 75 eps 0.687\nepisode 100 eps 0.606\nepisode 125 eps 0.534\nepisode 150 eps 0.471\nepisode 175 eps 0.416\nepisode 200 eps 0.367\nepisode 225 eps 0.324\nepisode 250 eps 0.286\nepisode 275 eps 0.252\nepisode 300 eps 0.222\nerdos | random           mean_AoI=2.104 ± 0.246\nerdos | greedy           mean_AoI=1.360 ± 0.112\nerdos | degree_weighted  mean_AoI=1.201 ± 0.113\nerdos | gnn_dqn_stable   mean_AoI=12.113 ± 2.276\n\nAction histogram for stable policy:\naction counts: [116  87   1   4 962 172   3  51  83  21]\naction probs : [0.077 0.058 0.001 0.003 0.641 0.115 0.002 0.034 0.055 0.014]\nSaved weights to: artifacts/gnn_dqn_stable_erdos.pt\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import torch, time\nprint(\"device:\", device)\nprint(\"cuda available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"GPU:\", torch.cuda.get_device_name(0))\n    print(\"cuda mem allocated (MB):\", torch.cuda.memory_allocated() / 1024**2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T07:16:10.367240Z","iopub.execute_input":"2025-12-22T07:16:10.367924Z","iopub.status.idle":"2025-12-22T07:16:10.373371Z","shell.execute_reply.started":"2025-12-22T07:16:10.367900Z","shell.execute_reply":"2025-12-22T07:16:10.372811Z"}},"outputs":[{"name":"stdout","text":"device: cuda\ncuda available: True\nGPU: Tesla T4\ncuda mem allocated (MB): 16.39697265625\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"def make_env(graph_type, seed, num_nodes=10, p=0.8, max_steps=50):\n    cfg = AoIEnvConfig(num_nodes=num_nodes, graph_type=graph_type, p=p, max_steps=max_steps, seed=seed)\n    env = AoIEnv(cfg)\n    cache_graph_tensors(env, device)\n    return env","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T07:16:24.114096Z","iopub.execute_input":"2025-12-22T07:16:24.114746Z","iopub.status.idle":"2025-12-22T07:16:24.118739Z","shell.execute_reply.started":"2025-12-22T07:16:24.114723Z","shell.execute_reply":"2025-12-22T07:16:24.117964Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"## Part 3b  Generalization across unseen graphs","metadata":{}},{"cell_type":"code","source":"import networkx as nx\nimport numpy as np\n\ndef _build_graph_fixed(self):\n    n = self.cfg.num_nodes\n\n    if self.cfg.graph_type == \"line\":\n        G = nx.path_graph(n)\n\n    elif self.cfg.graph_type == \"star\":\n        G = nx.star_graph(n - 1)\n\n    elif self.cfg.graph_type == \"erdos\":\n        p_edge = 0.3\n\n        # пробуем много разных seed, а не один и тот же\n        G = None\n        for _ in range(200):\n            sd = int(self.rng.randint(0, 2**31 - 1))\n            cand = nx.erdos_renyi_graph(n, p_edge, seed=sd)\n            if nx.is_connected(cand):\n                G = cand\n                break\n\n        # страховка: если вдруг не нашли связный, \"склеим\" компоненты вручную\n        if G is None:\n            sd = int(self.rng.randint(0, 2**31 - 1))\n            G = nx.erdos_renyi_graph(n, p_edge, seed=sd)\n            comps = list(nx.connected_components(G))\n            for c1, c2 in zip(comps[:-1], comps[1:]):\n                u = int(self.rng.choice(list(c1)))\n                v = int(self.rng.choice(list(c2)))\n                G.add_edge(u, v)\n\n    else:\n        raise ValueError(f\"Unknown graph_type: {self.cfg.graph_type}\")\n\n    self.graph = G\n\n# применяем патч\nAoIEnv._build_graph = _build_graph_fixed\nprint(\"Patched AoIEnv._build_graph\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T07:30:29.254916Z","iopub.execute_input":"2025-12-22T07:30:29.255472Z","iopub.status.idle":"2025-12-22T07:30:29.262830Z","shell.execute_reply.started":"2025-12-22T07:30:29.255446Z","shell.execute_reply":"2025-12-22T07:30:29.262008Z"}},"outputs":[{"name":"stdout","text":"Patched AoIEnv._build_graph\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"import numpy as np\nimport random\nimport torch\nimport torch.optim as optim\nfrom collections import deque\nfrom torch_geometric.data import Batch\nimport os\n\ndef make_pyg_batch(env, states_np):\n    data_list = [make_pyg_data(env, s, device) for s in states_np]\n    return Batch.from_data_list(data_list)\n\ndef train_gnn_dqn_generalize_v5(\n    episodes=800,\n    train_graph_type=\"erdos\",\n    num_nodes=10,\n    p=0.8,\n    max_steps=50,          # можно оставить 50\n    gamma=0.99,\n    lr=3e-4,\n    batch_size=32,         # <= max_steps\n    warmup_steps=32,       # <= max_steps\n    target_update=400,\n    eps_start=1.0,\n    eps_end=0.1,\n    eps_decay=0.9985,\n    reward_scale=None,     # если None, возьмём env.cfg.max_age\n    ep_replay_max=2000,    # достаточно\n    base_seed=3000,\n    log_every=50,\n    save_every=200,\n    save_prefix=\"artifacts/gnn_dqn_generalized_erdos_v5\"\n):\n    q_net = GNNQNet(in_dim=2, hidden=64).to(device)\n    target_net = GNNQNet(in_dim=2, hidden=64).to(device)\n    target_net.load_state_dict(q_net.state_dict())\n    target_net.eval()\n\n    opt = optim.Adam(q_net.parameters(), lr=lr)\n    loss_fn = torch.nn.SmoothL1Loss()\n\n    print(\"q_net device:\", next(q_net.parameters()).device)\n    os.makedirs(\"artifacts\", exist_ok=True)\n\n    eps = eps_start\n    total_steps = 0\n\n    for ep in range(episodes):\n        env = make_env(train_graph_type, seed=base_seed + ep, num_nodes=num_nodes, p=p, max_steps=max_steps)\n        scale = float(env.cfg.max_age) if reward_scale is None else float(reward_scale)\n\n        ep_replay = deque(maxlen=ep_replay_max)\n        s = env.reset()\n        ep_aoi_sum = 0.0\n        updates = 0\n\n        for t in range(env.cfg.max_steps):\n            if random.random() < eps:\n                a = random.randrange(env.action_n)\n            else:\n                with torch.no_grad():\n                    data = make_pyg_data(env, s, device)\n                    q = q_net(data)\n                    a = int(torch.argmax(q).item())\n\n            ns, r, done, info = env.step(a)\n            ep_aoi_sum += info[\"avg_aoi\"]\n\n            r_norm = r / scale\n            ep_replay.append((s, a, r_norm, ns, done))\n            s = ns\n\n            if len(ep_replay) >= max(warmup_steps, batch_size):\n                batch = random.sample(ep_replay, batch_size)\n                bs  = np.array([x[0] for x in batch])\n                ba  = np.array([x[1] for x in batch])\n                br  = np.array([x[2] for x in batch])\n                bns = np.array([x[3] for x in batch])\n                bd  = np.array([x[4] for x in batch])\n\n                batch_s = make_pyg_batch(env, bs)\n                N = env.num_nodes\n                q_all = q_net(batch_s).view(batch_size, N)\n                ba_t = torch.tensor(ba, dtype=torch.long, device=device)\n                q_sa = q_all[torch.arange(batch_size, device=device), ba_t]\n\n                with torch.no_grad():\n                    batch_ns = make_pyg_batch(env, bns)\n                    q_next = target_net(batch_ns).view(batch_size, N)\n                    q_next_max = q_next.max(dim=1).values\n\n                    br_t = torch.tensor(br, dtype=torch.float32, device=device)\n                    bd_t = torch.tensor(bd.astype(np.float32), dtype=torch.float32, device=device)\n                    target = br_t + gamma * (1.0 - bd_t) * q_next_max\n\n                loss = loss_fn(q_sa, target)\n                opt.zero_grad()\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(q_net.parameters(), 5.0)\n                opt.step()\n\n                updates += 1\n\n            total_steps += 1\n            if total_steps % target_update == 0:\n                target_net.load_state_dict(q_net.state_dict())\n\n            if done:\n                break\n\n        eps = max(eps_end, eps * eps_decay)\n\n        if (ep % log_every) == 0:\n            print(\"ep\", ep,\n                  \"eps\", round(eps, 3),\n                  \"mean_aoi_ep\", round(ep_aoi_sum / max_steps, 3),\n                  \"updates\", updates)\n\n        if (ep > 0) and (ep % save_every == 0):\n            path = f\"{save_prefix}_ep{ep}.pt\"\n            torch.save(q_net.state_dict(), path)\n            print(\"checkpoint saved:\", path)\n\n    final_path = f\"{save_prefix}.pt\"\n    torch.save(q_net.state_dict(), final_path)\n    print(\"final saved:\", final_path)\n    return q_net\n\nprint(\"Training generalized GNN-DQN v5 on ERDOS distribution...\")\nq_net_gen_v5 = train_gnn_dqn_generalize_v5()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T07:51:32.249730Z","iopub.execute_input":"2025-12-22T07:51:32.249999Z","iopub.status.idle":"2025-12-22T07:55:39.647314Z","shell.execute_reply.started":"2025-12-22T07:51:32.249979Z","shell.execute_reply":"2025-12-22T07:55:39.646444Z"}},"outputs":[{"name":"stdout","text":"Training generalized GNN-DQN v5 on ERDOS distribution...\nq_net device: cuda:0\nep 0 eps 0.999 mean_aoi_ep 1.796 updates 19\nep 50 eps 0.926 mean_aoi_ep 2.782 updates 19\nep 100 eps 0.859 mean_aoi_ep 3.19 updates 19\nep 150 eps 0.797 mean_aoi_ep 3.37 updates 19\nep 200 eps 0.74 mean_aoi_ep 1.698 updates 19\ncheckpoint saved: artifacts/gnn_dqn_generalized_erdos_v5_ep200.pt\nep 250 eps 0.686 mean_aoi_ep 2.874 updates 19\nep 300 eps 0.636 mean_aoi_ep 3.108 updates 19\nep 350 eps 0.59 mean_aoi_ep 2.062 updates 19\nep 400 eps 0.548 mean_aoi_ep 2.774 updates 19\ncheckpoint saved: artifacts/gnn_dqn_generalized_erdos_v5_ep400.pt\nep 450 eps 0.508 mean_aoi_ep 5.0 updates 19\nep 500 eps 0.471 mean_aoi_ep 3.604 updates 19\nep 550 eps 0.437 mean_aoi_ep 2.252 updates 19\nep 600 eps 0.406 mean_aoi_ep 2.908 updates 19\ncheckpoint saved: artifacts/gnn_dqn_generalized_erdos_v5_ep600.pt\nep 650 eps 0.376 mean_aoi_ep 3.982 updates 19\nep 700 eps 0.349 mean_aoi_ep 5.052 updates 19\nep 750 eps 0.324 mean_aoi_ep 2.79 updates 19\nfinal saved: artifacts/gnn_dqn_generalized_erdos_v5.pt\n","output_type":"stream"}],"execution_count":55},{"cell_type":"markdown","source":"### Evaluation and selection\nWe evaluate multiple checkpoints on unseen graphs and keep the best model.","metadata":{}},{"cell_type":"code","source":"import torch, numpy as np\n\ndef load_qnet(path):\n    q = GNNQNet(in_dim=2, hidden=64).to(device)\n    sd = torch.load(path, map_location=device)\n    q.load_state_dict(sd)\n    q.eval()\n    return q\n\ndef eval_family(q_net, graph_type, seeds, episodes_each=40, num_nodes=10, p=0.8, max_steps=50):\n    pol_gnn = gnn_policy_from_net(q_net, device)\n\n    out = {}\n    for name, pol in {\n        \"random\": random_policy,\n        \"greedy\": greedy_stale_policy,\n        \"degree_weighted\": degree_weighted_policy,\n        \"gnn_generalized\": pol_gnn\n    }.items():\n        ms = []\n        for sd in seeds:\n            env = make_env(graph_type, seed=sd, num_nodes=num_nodes, p=p, max_steps=max_steps)\n            m, _ = evaluate(env, pol, episodes=episodes_each)\n            ms.append(m)\n        out[name] = (float(np.mean(ms)), float(np.std(ms)))\n    return out\n\ncheckpoints = [\n    \"artifacts/gnn_dqn_generalized_erdos_v5_ep200.pt\",\n    \"artifacts/gnn_dqn_generalized_erdos_v5_ep400.pt\",\n    \"artifacts/gnn_dqn_generalized_erdos_v5_ep600.pt\",\n    \"artifacts/gnn_dqn_generalized_erdos_v5.pt\",\n]\n\ntests = {\n    \"erdos_new\": (\"erdos\", [900, 901, 902, 903, 904]),\n    \"line\":      (\"line\",  [910, 911, 912]),\n    \"star\":      (\"star\",  [920, 921, 922]),\n}\n\nsummary = []\n\nfor ckpt in checkpoints:\n    q = load_qnet(ckpt)\n    res_erdos = eval_family(q, \"erdos\", [900, 901, 902, 903, 904], episodes_each=40)\n    m = res_erdos[\"gnn_generalized\"][0]\n    summary.append((ckpt, m))\n    print(\"\\nCKPT:\", ckpt)\n    print(\"erdos_new | gnn_generalized mean_AoI=\", round(m, 3),\n          \"| degree_weighted=\", round(res_erdos[\"degree_weighted\"][0], 3),\n          \"| greedy=\", round(res_erdos[\"greedy\"][0], 3))\n\nbest_ckpt = sorted(summary, key=lambda x: x[1])[0][0]\nprint(\"\\nBEST checkpoint by erdos_new:\", best_ckpt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T08:05:21.160956Z","iopub.execute_input":"2025-12-22T08:05:21.161779Z","iopub.status.idle":"2025-12-22T08:06:27.225131Z","shell.execute_reply.started":"2025-12-22T08:05:21.161748Z","shell.execute_reply":"2025-12-22T08:06:27.224460Z"}},"outputs":[{"name":"stdout","text":"\nCKPT: artifacts/gnn_dqn_generalized_erdos_v5_ep200.pt\nerdos_new | gnn_generalized mean_AoI= 5.902 | degree_weighted= 1.431 | greedy= 1.622\n\nCKPT: artifacts/gnn_dqn_generalized_erdos_v5_ep400.pt\nerdos_new | gnn_generalized mean_AoI= 7.272 | degree_weighted= 1.431 | greedy= 1.622\n\nCKPT: artifacts/gnn_dqn_generalized_erdos_v5_ep600.pt\nerdos_new | gnn_generalized mean_AoI= 5.407 | degree_weighted= 1.431 | greedy= 1.622\n\nCKPT: artifacts/gnn_dqn_generalized_erdos_v5.pt\nerdos_new | gnn_generalized mean_AoI= 4.194 | degree_weighted= 1.431 | greedy= 1.622\n\nBEST checkpoint by erdos_new: artifacts/gnn_dqn_generalized_erdos_v5.pt\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"best_q = load_qnet(best_ckpt)\n\nfor label, (gtype, seeds) in tests.items():\n    res = eval_family(best_q, gtype, seeds, episodes_each=40)\n    print(\"\\nTEST\", label, \"graph\", gtype)\n    for k in [\"random\", \"greedy\", \"degree_weighted\", \"gnn_generalized\"]:\n        m, s = res[k]\n        print(f\"{k:15s} mean_AoI={m:.3f}  (std over seeds {s:.3f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T08:06:27.226426Z","iopub.execute_input":"2025-12-22T08:06:27.226934Z","iopub.status.idle":"2025-12-22T08:07:03.550821Z","shell.execute_reply.started":"2025-12-22T08:06:27.226914Z","shell.execute_reply":"2025-12-22T08:07:03.550078Z"}},"outputs":[{"name":"stdout","text":"\nTEST erdos_new graph erdos\nrandom          mean_AoI=2.345  (std over seeds 0.380)\ngreedy          mean_AoI=1.622  (std over seeds 0.257)\ndegree_weighted mean_AoI=1.431  (std over seeds 0.162)\ngnn_generalized mean_AoI=4.194  (std over seeds 1.377)\n\nTEST line graph line\nrandom          mean_AoI=3.298  (std over seeds 0.034)\ngreedy          mean_AoI=2.105  (std over seeds 0.009)\ndegree_weighted mean_AoI=2.008  (std over seeds 0.018)\ngnn_generalized mean_AoI=1.856  (std over seeds 0.019)\n\nTEST star graph star\nrandom          mean_AoI=4.090  (std over seeds 0.173)\ngreedy          mean_AoI=3.640  (std over seeds 0.025)\ndegree_weighted mean_AoI=2.069  (std over seeds 0.018)\ngnn_generalized mean_AoI=0.250  (std over seeds 0.005)\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"import shutil, os\nos.makedirs(\"artifacts\", exist_ok=True)\nshutil.copy(best_ckpt, \"artifacts/gnn_dqn_generalized_best.pt\")\nprint(\"Saved best checkpoint to artifacts/gnn_dqn_generalized_best.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T08:07:03.552484Z","iopub.execute_input":"2025-12-22T08:07:03.552700Z","iopub.status.idle":"2025-12-22T08:07:03.557454Z","shell.execute_reply.started":"2025-12-22T08:07:03.552683Z","shell.execute_reply":"2025-12-22T08:07:03.556719Z"}},"outputs":[{"name":"stdout","text":"Saved best checkpoint to artifacts/gnn_dqn_generalized_best.pt\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"import numpy as np\n\ndef action_histogram(q_net, graph_type=\"star\", seed=123, steps=1000):\n    env = make_env(graph_type, seed=seed, num_nodes=10, p=0.8, max_steps=50)\n    pol = gnn_policy_from_net(q_net, device)\n\n    counts = np.zeros(env.action_n, dtype=int)\n    s = env.reset()\n\n    for _ in range(steps):\n        a = pol(s, env)\n        counts[a] += 1\n        s, r, done, info = env.step(a)\n        if done:\n            s = env.reset()\n\n    probs = counts / counts.sum()\n    print(\"graph:\", graph_type)\n    print(\"action counts:\", counts)\n    print(\"action probs :\", np.round(probs, 3))\n\nbest_q = load_qnet(\"artifacts/gnn_dqn_generalized_best.pt\")\naction_histogram(best_q, \"star\", seed=777, steps=2000)\naction_histogram(best_q, \"line\", seed=888, steps=2000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T08:13:43.962328Z","iopub.execute_input":"2025-12-22T08:13:43.962612Z","iopub.status.idle":"2025-12-22T08:13:50.230277Z","shell.execute_reply.started":"2025-12-22T08:13:43.962591Z","shell.execute_reply":"2025-12-22T08:13:50.229632Z"}},"outputs":[{"name":"stdout","text":"graph: star\naction counts: [2000    0    0    0    0    0    0    0    0    0]\naction probs : [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\ngraph: line\naction counts: [  1 623  10 182 187 198 165  24 610   0]\naction probs : [0.    0.312 0.005 0.091 0.094 0.099 0.082 0.012 0.305 0.   ]\n","output_type":"stream"}],"execution_count":68},{"cell_type":"markdown","source":"## Reflection and observations\n\nIn this project, I studied Age of Information minimization on graphs using reinforcement learning.\n\nIn Part 3a, a GNN-DQN agent was trained on fixed graph types. In this setting, the learned policy showed reasonable behavior and achieved competitive performance compared to simple baselines on structured graphs.\n\nIn Part 3b, I trained a generalized GNN-DQN on a distribution of Erdos graphs and evaluated it on unseen graphs. The results show that the learned policy generalizes well to star and line graphs, but consistently underperforms simple heuristic baselines on random Erdos graphs.\n\nThis indicates that generalization across graph families is non-trivial and that simple heuristics remain strong baselines for AoI minimization. The experiments highlight the importance of careful evaluation and show that increased model complexity does not guarantee better performance.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}